<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Advanced RNN LSTM | SHINYUU BLOG</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-108690246-1','auto');ga('send','pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Advanced RNN LSTM</h1><a id="logo" href="/.">SHINYUU BLOG</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Advanced RNN LSTM</h1><div class="post-meta">Jul 17, 2018</div><div class="post-content"><p>Long Short-Term Memory (LSTM) Networks refers to a type of  RNN capable of learning to store information over extended time intervals in sequence prediction problems. The expression long short-term refers to the fact that LSTM is a model for the short-term memory which can last for a long period of time. LSTM was proposed in 1997 by Hochreiter and Schmidhuber. At present, it has achieved considerable success and has been widely used in many areas like machine translation and speech recognition.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p><img src="http://oyer09cam.bkt.clouddn.com/blog/180718/e6cma1miig.png" alt="Architectures of a LSTM Block "></p>
<p>Look at the above picture, compared with RNN introduced before, you’ll find that the big difference just lies in the internal structure of each block. So, here we focus on figuring out the components inside the LSTM block, in other words, the paths marked by arrows inside the picture. </p>
<h3 id="Three-Gates"><a href="#Three-Gates" class="headerlink" title="Three Gates"></a>Three Gates</h3><p>Suppose at time step $t$, the input includes data $\boldsymbol{X}_t \in \mathbb{R}^{n \times d}$ and hidden state $\boldsymbol{H}_{t-1} \in \mathbb{R}^{n \times h}$. A common LSTM block is composed of an <strong>input</strong> gate $\boldsymbol{I}_t \in \mathbb{R}^{n \times h}$, an <strong>output</strong> gate $\boldsymbol{O}_t \in \mathbb{R}^{n \times h}$ and a <strong>forget</strong> gate $\boldsymbol{F}_t \in \mathbb{R}^{n \times h}$.<br>$$\boldsymbol{I}_t = \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xi} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hi} + \boldsymbol{b}_i)$$</p>
<p>$$\boldsymbol{F}_t = \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xf} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hf} + \boldsymbol{b}_f)$$</p>
<p>$$\boldsymbol{O}_t = \sigma(\boldsymbol{X}_t \boldsymbol{W}_{xo} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{ho} + \boldsymbol{b}_o)  $$</p>
<h3 id="Two-Memories"><a href="#Two-Memories" class="headerlink" title="Two Memories"></a>Two Memories</h3><p><img src="http://oyer09cam.bkt.clouddn.com/blog/180718/5B9KeI163E.png" alt="Two Kinds of Memories"><br>The long-term memory, usually called the cell state, it’s the key to LSTM. For simplicity, before finally getting memory cell $\boldsymbol{C}_t$, we first introduce what we call candidate memory cell $\tilde{\boldsymbol{C}}_t$.</p>
<p>$$\tilde{\boldsymbol{C}}_t = \text{tanh}(\boldsymbol{X}_t \boldsymbol{W}_{xc} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hc} + \boldsymbol{b}_c)$$</p>
<p>Next, with the help of the input &amp; forget  gates, we could derive $\boldsymbol{C}_t$ from  $\tilde{\boldsymbol{C}}_t$ and $\boldsymbol{C}_{t-1}$.<br>$$\boldsymbol{C}_t = \boldsymbol{F}_t \odot \boldsymbol{C}_{t-1} + \boldsymbol{I}_t \odot \tilde{\boldsymbol{C}}_t$$</p>
<p>The working memory, usually called the hidden state, analogous to the hidden state in vanilla RNNs, is then</p>
<p>$$\boldsymbol{H}_t = \boldsymbol{O}_t \odot \text{tanh}(\boldsymbol{C}_t)$$</p>
<p>Actually, it’s easy to see that the input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM block. </p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1]: <em>Aston Zhang, Mu Li</em>. Gluon-tutorials-zh.<br>[2]: <em>wikipedia</em>. wiki/Long_short-term_memory.</p>
</div><div class="tags"><a href="/tags/NeuralNetwork/">NeuralNetwork</a></div><div class="post-nav"><a href="/RNN/" class="next">Introduction of RNN</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://yoursite.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/NeuralNetwork/" style="font-size: 15px;">NeuralNetwork</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/LSTM/">Advanced RNN LSTM</a></li><li class="post-list-item"><a class="post-list-link" href="/RNN/">Introduction of RNN</a></li><li class="post-list-item"><a class="post-list-link" href="/KaggleCompetition/">Experience in a Kaggle Competition</a></li><li class="post-list-item"><a class="post-list-link" href="/StyleTransfer/">Style Transfer</a></li><li class="post-list-item"><a class="post-list-link" href="/Linux/">Linux Basic Operation</a></li><li class="post-list-item"><a class="post-list-link" href="/TrickCNN/">Tricks for CNN Coding</a></li><li class="post-list-item"><a class="post-list-link" href="/GooglenetResnet/">Advanced CNN GoogLeNet, ResNet & DenseNet</a></li><li class="post-list-item"><a class="post-list-link" href="/AlexnetVgg/">Advanced CNN AlexNet & VGG</a></li><li class="post-list-item"><a class="post-list-link" href="/CNN/">Introduction of CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/MLP/">Multilayer Perceptron</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://sites.google.com/view/lixinyuhomepage" title="Homepage" target="_blank">Homepage</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">SHINYUU BLOG.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>