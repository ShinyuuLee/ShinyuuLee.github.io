<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>An Example of Python Web Crawler | SHINYUU BLOG</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-108690246-1','auto');ga('send','pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">An Example of Python Web Crawler</h1><a id="logo" href="/.">SHINYUU BLOG</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">An Example of Python Web Crawler</h1><div class="post-meta">Sep 2, 2018</div><div class="post-content"><p>A web crawler, sometimes called a spider or spiderbot, always plays an important role in the process of extracting the data we need from websites, named web crawling or spidering. Python provides us some powerful tools to achieve the goal, such as scrapy. In this essay, we give a piece of code to show how to write a simple web crawler, whose purpose is to get the news data from sina.<br>It should be noted that the sina news website framework often changes, so this code may be out-of-date after a period of time.</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div><div class="line"></div><div class="line">commentURL = <span class="string">'http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;channel=gj&amp;newsid=comos-&#123;&#125;&amp;group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;page_size=3&amp;t_size=3&amp;h_size=3&amp;thread=1'</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCommentCount</span><span class="params">(newsurl)</span>:</span></div><div class="line">    m = re.search(<span class="string">'doc-i(.+).shtml'</span>,newsurl)</div><div class="line">    newsid = m.group(<span class="number">1</span>)</div><div class="line">    comments = requests.get(commentURL.format(newsid))</div><div class="line">    jd = json.loads(comments.text)</div><div class="line">    <span class="keyword">return</span> jd[<span class="string">'result'</span>][<span class="string">'count'</span>][<span class="string">'total'</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNewsDetail</span><span class="params">(newsurl)</span>:</span></div><div class="line">    result = &#123;&#125;</div><div class="line">    res = requests.get(newsurl)</div><div class="line">    res.encoding = <span class="string">'utf-8'</span></div><div class="line">    soup = BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        result[<span class="string">'title'</span>] = soup.select(<span class="string">'.main-title'</span>)[<span class="number">0</span>].text</div><div class="line">        result[<span class="string">'newssource'</span>] = soup.select(<span class="string">'.date'</span>)[<span class="number">0</span>].text</div><div class="line">        result[<span class="string">'dt'</span>] = datetime.strptime(soup.select(<span class="string">'.date-source'</span>)[<span class="number">0</span>].contents[<span class="number">1</span>].text.strip(),<span class="string">'%Y年%m月%d日 %H:%M'</span>)</div><div class="line">        result[<span class="string">'article'</span>] = <span class="string">' '</span>.join([p.text.strip() <span class="keyword">for</span> p <span class="keyword">in</span> soup.select(<span class="string">'#article p'</span>)[:<span class="number">-1</span>]])</div><div class="line">        result[<span class="string">'editor'</span>] = soup.select(<span class="string">'.show_author'</span>)[<span class="number">0</span>].text.strip(<span class="string">'责任编辑：'</span>).strip()</div><div class="line">        result[<span class="string">'comments'</span>] = getCommentCount(newsurl)</div><div class="line">    <span class="keyword">except</span> OSError:</div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> result</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseListLinks</span><span class="params">(url)</span>:</span></div><div class="line">    newsdetails = []</div><div class="line">    res = requests.get(url)</div><div class="line">    jd = json.loads(res.text.lstrip(<span class="string">'newsloadercallback('</span>).rstrip(<span class="string">')\n'</span>) )    </div><div class="line">    <span class="keyword">for</span> ent <span class="keyword">in</span> jd[<span class="string">'result'</span>][<span class="string">'data'</span>]:</div><div class="line">        newsdetails.append(getNewsDetail(ent[<span class="string">'url'</span>]))</div><div class="line">    <span class="keyword">return</span> newsdetails</div><div class="line">    </div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</div><div class="line">    </div><div class="line">    url = <span class="string">'https://interface.sina.cn/news/get_news_by_channel_new_v2018.d.html?cat_1=51923&amp;show_num=27&amp;level=1,2&amp;page=&#123;&#125;&amp;callback=newsloadercallback'</span></div><div class="line">    newstotal = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">3</span>):</div><div class="line">        newsurl = url.format(i)</div><div class="line">        newsary = parseListLinks(newsurl)</div><div class="line">        newstotal.extend(newsary)</div><div class="line">        </div><div class="line">    print(len(newstotal))</div><div class="line">    </div><div class="line">    <span class="keyword">import</span> pandas</div><div class="line">    df = pandas.DataFrame(newstotal)</div><div class="line">    df.to_excel(<span class="string">'sina_news.xlsx'</span>)</div></pre></td></tr></table></figure>
<p><img src="http://oyer09cam.bkt.clouddn.com/blog/180902/ehh9aBimAa.png" alt="News Collected Display"></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1]: <em>David Chiu</em>.  Videos for teaching python web crawler.</p>
</div><div class="tags"><a href="/tags/Python/">Python</a></div><div class="post-nav"><a href="/PythonPlot/" class="next">Plotting with Python</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://yoursite.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/NeuralNetwork/" style="font-size: 15px;">NeuralNetwork</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/WebScrawler/">An Example of Python Web Crawler</a></li><li class="post-list-item"><a class="post-list-link" href="/PythonPlot/">Plotting with Python</a></li><li class="post-list-item"><a class="post-list-link" href="/LSTM/">Advanced RNN LSTM</a></li><li class="post-list-item"><a class="post-list-link" href="/RNN/">Introduction of RNN</a></li><li class="post-list-item"><a class="post-list-link" href="/KaggleCompetition/">Experience in a Kaggle Competition</a></li><li class="post-list-item"><a class="post-list-link" href="/StyleTransfer/">Style Transfer</a></li><li class="post-list-item"><a class="post-list-link" href="/Linux/">Linux Basic Operation</a></li><li class="post-list-item"><a class="post-list-link" href="/TrickCNN/">Tricks for CNN Coding</a></li><li class="post-list-item"><a class="post-list-link" href="/GooglenetResnet/">Advanced CNN GoogLeNet, ResNet & DenseNet</a></li><li class="post-list-item"><a class="post-list-link" href="/AlexnetVgg/">Advanced CNN AlexNet & VGG</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://sites.google.com/view/lixinyuhomepage" title="Homepage" target="_blank">Homepage</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">SHINYUU BLOG.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>